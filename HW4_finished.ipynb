{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pymorphy2 # Морфологический анализатор.\n",
    "from collections import Counter # Не считать же частоты самим.\n",
    "import math # Корень квадратный.\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', sep='\\t', encoding='utf8', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph=pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeaningfullWords(text):\n",
    "    words=[]\n",
    "    tokens=re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', text)\n",
    "    for t in tokens:\n",
    "        pv=morph.parse(t)\n",
    "        for p in pv:\n",
    "            if p.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                words.append(p.normal_form)\n",
    "                break\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "10000 \n",
      "\n",
      "20000 \n",
      "\n",
      "30000 \n",
      "\n",
      "40000 \n",
      "\n",
      "50000 \n",
      "\n",
      "60000 \n",
      "\n",
      "70000 \n",
      "\n",
      "80000 \n",
      "\n",
      "90000 \n",
      "\n",
      "100000 \n",
      "\n",
      "110000 \n",
      "\n",
      "120000 \n",
      "\n",
      "130000 \n",
      "\n",
      "140000 \n",
      "\n",
      "150000 \n",
      "\n",
      "160000 \n",
      "\n",
      "170000 \n",
      "\n",
      "180000 \n",
      "\n",
      "190000 \n",
      "\n",
      "Wall time: 33min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_tokens=[]\n",
    "text_tokens=[]\n",
    "pos_list = []\n",
    "for i in df_train.index:\n",
    "    if i % 10000 == 0:\n",
    "        print(i,\"\\n\")\n",
    "    if df_train.iloc[i:i+1,2][i] == 1:\n",
    "        bs=BeautifulSoup(df_train.iloc[i:i+1,1][i], \"html5lib\")\n",
    "        title_tokens=re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', df_train.iloc[i:i+1,0][i])\n",
    "        text_tokens=re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', BeautifulSoup(\" \".join([p.text for p in bs.find_all(\"li\")]), \"html5lib\").get_text())\n",
    "        tokens=title_tokens+text_tokens\n",
    "        for t in tokens:\n",
    "            pv=morph.parse(t)\n",
    "            for p in pv:\n",
    "                if p.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                    pos_list.append(p.normal_form)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cc=[' '.join(pos_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lemmaCounter=CountVectorizer(ngram_range=(1,2), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix=pos_lemmaCounter.fit_transform(pos_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 536419)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "10000 \n",
      "\n",
      "20000 \n",
      "\n",
      "30000 \n",
      "\n",
      "40000 \n",
      "\n",
      "50000 \n",
      "\n",
      "60000 \n",
      "\n",
      "70000 \n",
      "\n",
      "80000 \n",
      "\n",
      "90000 \n",
      "\n",
      "100000 \n",
      "\n",
      "110000 \n",
      "\n",
      "120000 \n",
      "\n",
      "130000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000 \n",
      "\n",
      "150000 \n",
      "\n",
      "160000 \n",
      "\n",
      "170000 \n",
      "\n",
      "180000 \n",
      "\n",
      "190000 \n",
      "\n",
      "Wall time: 31min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_tokens=[]\n",
    "text_tokens=[]\n",
    "neg_list = []\n",
    "for i in df_train.index:\n",
    "    if i % 10000 == 0:\n",
    "        print(i,\"\\n\")\n",
    "    if df_train.iloc[i:i+1,2][i] == 0:\n",
    "        bs=BeautifulSoup(df_train.iloc[i:i+1,1][i], \"html5lib\")\n",
    "        title_tokens=re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', df_train.iloc[i:i+1,0][i])\n",
    "        text_tokens=re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', BeautifulSoup(\" \".join([p.text for p in bs.find_all(\"li\")]), \"html5lib\").get_text())\n",
    "        tokens=title_tokens+text_tokens\n",
    "        for t in tokens:\n",
    "            pv=morph.parse(t)\n",
    "            for p in pv:\n",
    "                if p.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                    neg_list.append(p.normal_form)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_cc=[' '.join(neg_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_lemmaCounter=CountVectorizer(ngram_range=(1,2), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_matrix=neg_lemmaCounter.fit_transform(neg_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 816355)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_zero_matrix = np.zeros((pos_matrix.shape[0],pos_matrix.shape[1]))\n",
    "neg_zero_matrix = np.zeros((neg_matrix.shape[0],neg_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 536419)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_zero_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 816355)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_zero_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', sep='\\t', encoding='utf8', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170179, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_zero_matrix = np.zeros((pos_matrix.shape[0],pos_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 536419)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos_zero_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><strong>Обязанности:</strong></p> <ul> <li>Работа с клиентом в салоне,выезд на замер ,создание дизайн-проекта,расчеты,ведение документации,заключение договоров</li> </ul> <p> </p> <p><strong>Требования:</strong></p> <ul> <li>Опыт работы желателен,уверенный пользователь ПК,грамотная речь,желание учиться и развиваться</li> </ul> <p> </p> <p><strong>Условия:</strong></p> <ul> <li>Трудоустройство по ТК, обучение+стажировка,оклад+% от личных продаж,удобный график</li> </ul>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[:1,1][200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lemmaCounter=CountVectorizer(ngram_range=(1,2), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "bs_test=BeautifulSoup(df_test.iloc[:1,1][200000], \"html5lib\")\n",
    "test_row=[' '.join(getMeaningfullWords(df_test.iloc[:1,0][200000]+' '+BeautifulSoup(\" \".join([p.text for p in bs_test.find_all(\"li\")]), \"html5lib\").get_text()))]\n",
    "test_row_matrix=test_lemmaCounter.fit_transform(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in test_lemmaCounter.vocabulary_:\n",
    "    if str(pos_lemmaCounter.vocabulary_.get(w)) != 'None':\n",
    "        test_pos_zero_matrix[0,pos_lemmaCounter.vocabulary_[w]] = test_row_matrix[0,test_lemmaCounter.vocabulary_[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lemmaCounter.vocabulary_[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488832"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lemmaCounter.vocabulary_[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_zero_sparse_matrix = sparse.csr_matrix(test_pos_zero_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39948663]]\n"
     ]
    }
   ],
   "source": [
    "res_array = cosine_similarity(pos_matrix, test_pos_zero_sparse_matrix)\n",
    "print(res_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3994866347084164"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_zero_matrix = np.zeros((neg_matrix.shape[0],neg_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 816355)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neg_zero_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in test_lemmaCounter.vocabulary_:\n",
    "    if str(neg_lemmaCounter.vocabulary_.get(w)) != 'None':\n",
    "        test_neg_zero_matrix[0,neg_lemmaCounter.vocabulary_[w]] = test_row_matrix[0,test_lemmaCounter.vocabulary_[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_zero_sparse_matrix = sparse.csr_matrix(test_neg_zero_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34450664]]\n"
     ]
    }
   ],
   "source": [
    "neg_res_array = cosine_similarity(neg_matrix, test_neg_zero_sparse_matrix)\n",
    "print(neg_res_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.344506636514514"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_res_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200001"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.index[:5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "10000 \n",
      "\n",
      "20000 \n",
      "\n",
      "30000 \n",
      "\n",
      "40000 \n",
      "\n",
      "50000 \n",
      "\n",
      "60000 \n",
      "\n",
      "70000 \n",
      "\n",
      "80000 \n",
      "\n",
      "90000 \n",
      "\n",
      "100000 \n",
      "\n",
      "110000 \n",
      "\n",
      "120000 \n",
      "\n",
      "130000 \n",
      "\n",
      "140000 \n",
      "\n",
      "150000 \n",
      "\n",
      "160000 \n",
      "\n",
      "170000 \n",
      "\n",
      "Wall time: 3h 5min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos_zero_matrix = np.zeros((pos_matrix.shape[0],pos_matrix.shape[1]))\n",
    "neg_zero_matrix = np.zeros((neg_matrix.shape[0],neg_matrix.shape[1]))\n",
    "res_lemmaCounter=CountVectorizer(ngram_range=(1,2), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "j = 0\n",
    "result_df = pd.DataFrame(columns=['target'], index=df_test.index)\n",
    "for i in df_test.index:\n",
    "    if j % 10000 == 0:\n",
    "        print(j,\"\\n\")\n",
    "    bs_test=BeautifulSoup(df_test.iloc[j:j+1,1][i], \"html5lib\")\n",
    "    test_row=[' '.join(getMeaningfullWords(df_test.iloc[j:j+1,0][i]+' '+BeautifulSoup(\" \".join([p.text for p in bs_test.find_all(\"li\")]), \"html5lib\").get_text()))]\n",
    "    if len(test_row[0]) > 0:\n",
    "        test_row_matrix=res_lemmaCounter.fit_transform(test_row)\n",
    "        pos_zero_matrix.fill(0)\n",
    "        for w in res_lemmaCounter.vocabulary_:\n",
    "            if str(pos_lemmaCounter.vocabulary_.get(w)) != 'None':\n",
    "                pos_zero_matrix[0,pos_lemmaCounter.vocabulary_[w]] = test_row_matrix[0,res_lemmaCounter.vocabulary_[w]]\n",
    "        pos_zero_sparse_matrix = sparse.csr_matrix(pos_zero_matrix)\n",
    "        pos_res_array = cosine_similarity(pos_matrix, pos_zero_sparse_matrix)\n",
    "        neg_zero_matrix.fill(0)\n",
    "        for w in res_lemmaCounter.vocabulary_:\n",
    "            if str(neg_lemmaCounter.vocabulary_.get(w)) != 'None':\n",
    "                neg_zero_matrix[0,neg_lemmaCounter.vocabulary_[w]] = test_row_matrix[0,res_lemmaCounter.vocabulary_[w]]\n",
    "        neg_zero_sparse_matrix = sparse.csr_matrix(neg_zero_matrix)\n",
    "        neg_res_array = cosine_similarity(neg_matrix, neg_zero_sparse_matrix)\n",
    "        if pos_res_array[0][0] > neg_res_array[0][0]:\n",
    "            result_df.loc[i:i+1, 'target'] = 1\n",
    "        else:\n",
    "            result_df.loc[i:i+1, 'target'] = 0\n",
    "    else:\n",
    "        result_df.loc[i:i+1, 'target'] = 0\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    85686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['target']==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    84493\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['target']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200005</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200007</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200008</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200009</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200010</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200011</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200012</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200013</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200014</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200015</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200016</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200017</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200019</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200020</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200021</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200023</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200024</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200025</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200026</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200027</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200028</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200029</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200070</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200071</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200072</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200073</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200074</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200075</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200076</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200077</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200078</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200079</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200080</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200081</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200082</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200083</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200084</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200085</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200086</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200087</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200088</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200089</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200090</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200091</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200092</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200093</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200094</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200095</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200096</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200097</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200098</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200099</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target\n",
       "id            \n",
       "200000       1\n",
       "200001       1\n",
       "200002       1\n",
       "200003       1\n",
       "200004       0\n",
       "200005       0\n",
       "200006       1\n",
       "200007       1\n",
       "200008       0\n",
       "200009       0\n",
       "200010       1\n",
       "200011       1\n",
       "200012       0\n",
       "200013       1\n",
       "200014       1\n",
       "200015       1\n",
       "200016       1\n",
       "200017       1\n",
       "200018       1\n",
       "200019       1\n",
       "200020       1\n",
       "200021       1\n",
       "200022       1\n",
       "200023       0\n",
       "200024       1\n",
       "200025       1\n",
       "200026       1\n",
       "200027       0\n",
       "200028       0\n",
       "200029       1\n",
       "...        ...\n",
       "200070       1\n",
       "200071       1\n",
       "200072       0\n",
       "200073       0\n",
       "200074       1\n",
       "200075       0\n",
       "200076       0\n",
       "200077       0\n",
       "200078       0\n",
       "200079       0\n",
       "200080       0\n",
       "200081       1\n",
       "200082       1\n",
       "200083       0\n",
       "200084       0\n",
       "200085       1\n",
       "200086       1\n",
       "200087       0\n",
       "200088       0\n",
       "200089       0\n",
       "200090       1\n",
       "200091       1\n",
       "200092       0\n",
       "200093       1\n",
       "200094       1\n",
       "200095       0\n",
       "200096       0\n",
       "200097       0\n",
       "200098       0\n",
       "200099       1\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('submission.csv', sep=',', encoding='utf-8', index='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
